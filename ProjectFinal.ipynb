{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17557cb-17d0-46ae-ad5b-37cf688bf84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2d923a-988a-4e76-bda6-7567cd73ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(cv2.samples.findFile(\"f1-manager-advanced-guide-400x400.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871e2774-91a7-40f0-af21-c96fa57839b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663f978f-6453-433f-9222-34ec251d85ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Myimage\", img) \n",
    "k= cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7297b348-4ba4-4481-8290-6bb3909b44d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('frame', gray)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f8442-8f2e-4e85-8c0a-8bf6ff4e8f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('frame', gray)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82dc7da-ca03-4d1e-ba5a-83fa1ae0c6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86534c50-69b7-4558-8bd3-9c0aa0113f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('window', gray)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb72dd-6bd4-403c-8bc0-30fa75e62a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "thy = 5\n",
    "print(thy)\n",
    "thy = 'five'\n",
    "print(thy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8679f38d-7a17-467e-8d39-0f485b2e4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "cap = cv.VideoCapture(1)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('window', gray)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f528aca-bb82-4396-baf9-8ce8a0c4992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "cap = cv.VideoCapture(2)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('window', gray)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9931614-3935-4183-838e-4290e9a55b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "cap = cv.VideoCapture(1)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('window', gray)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba813ac3-592c-4ef3-b6b0-3703404f5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "cap = cv.VideoCapture(2)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('window', gray)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8179f335-d9f8-4d60-95d9-8a8c8f3dcb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    # gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('window', frame)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21445b2-cb34-4ceb-a79d-a573fda1e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "def detectAndDisplay(frame):\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv.equalizeHist(frame_gray)\n",
    "    #-- Detect faces\n",
    "    faces = face_cascade.detectMultiScale(frame_gray)\n",
    "    for (x,y,w,h) in faces:\n",
    "        center = (x + w//2, y + h//2)\n",
    "        frame = cv.ellipse(frame, center, (w//2, h//2), 0, 0, 360, (255, 0, 255), 4)\n",
    "        faceROI = frame_gray[y:y+h,x:x+w]\n",
    "        #-- In each face, detect eyes\n",
    "        eyes = eyes_cascade.detectMultiScale(faceROI)\n",
    "        for (x2,y2,w2,h2) in eyes:\n",
    "            eye_center = (x + x2 + w2//2, y + y2 + h2//2)\n",
    "            radius = int(round((w2 + h2)*0.25))\n",
    "            frame = cv.circle(frame, eye_center, radius, (255, 0, 0 ), 4)\n",
    "    cv.imshow('Capture - Face detection', frame)\n",
    "parser = argparse.ArgumentParser(description='Code for Cascade Classifier tutorial.')\n",
    "parser.add_argument('--face_cascade', help='Path to face cascade.', default='data/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "parser.add_argument('--eyes_cascade', help='Path to eyes cascade.', default='data/haarcascades/haarcascade_eye_tree_eyeglasses.xml')\n",
    "parser.add_argument('--camera', help='Camera divide number.', type=int, default=0)\n",
    "args = parser.parse_args()\n",
    "face_cascade_name = args.face_cascade\n",
    "eyes_cascade_name = args.eyes_cascade\n",
    "face_cascade = cv.CascadeClassifier()\n",
    "eyes_cascade = cv.CascadeClassifier()\n",
    "#-- 1. Load the cascades\n",
    "if not face_cascade.load(cv.samples.findFile(face_cascade_name)):\n",
    "    print('--(!)Error loading face cascade')\n",
    "    exit(0)\n",
    "if not eyes_cascade.load(cv.samples.findFile(eyes_cascade_name)):\n",
    "    print('--(!)Error loading eyes cascade')\n",
    "    exit(0)\n",
    "camera_device = args.camera\n",
    "#-- 2. Read the video stream\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened:\n",
    "    print('--(!)Error opening video capture')\n",
    "    exit(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        print('--(!) No captured frame -- Break!')\n",
    "        break\n",
    "    detectAndDisplay(frame)\n",
    "    if cv.waitKey(10) == 27:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00657f2a-977d-4b20-b68b-ffa9965ffce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "def detectAndDisplay(frame):\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv.equalizeHist(frame_gray)\n",
    "    #-- Detect faces\n",
    "    faces = face_cascade.detectMultiScale(frame_gray)\n",
    "    for (x,y,w,h) in faces:\n",
    "        center = (x + w//2, y + h//2)\n",
    "        frame = cv.ellipse(frame, center, (w//2, h//2), 0, 0, 360, (255, 0, 255), 4)\n",
    "        faceROI = frame_gray[y:y+h,x:x+w]\n",
    "        #-- In each face, detect eyes\n",
    "        eyes = eyes_cascade.detectMultiScale(faceROI)\n",
    "        for (x2,y2,w2,h2) in eyes:\n",
    "            eye_center = (x + x2 + w2//2, y + y2 + h2//2)\n",
    "            radius = int(round((w2 + h2)*0.25))\n",
    "            frame = cv.circle(frame, eye_center, radius, (255, 0, 0 ), 4)\n",
    "    cv.imshow('Capture - Face detection', frame)\n",
    "parser = argparse.ArgumentParser(description='Code for Cascade Classifier tutorial.')\n",
    "parser.add_argument('--face_cascade', help='Path to face cascade.', default='data/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "parser.add_argument('--eyes_cascade', help='Path to eyes cascade.', default='data/haarcascades/haarcascade_eye_tree_eyeglasses.xml')\n",
    "parser.add_argument('--camera', help='Camera divide number.', type=int, default=0)\n",
    "args = parser.parse_args()\n",
    "face_cascade_name = args.face_cascade\n",
    "eyes_cascade_name = args.eyes_cascade\n",
    "face_cascade = cv.CascadeClassifier()\n",
    "eyes_cascade = cv.CascadeClassifier()\n",
    "#-- 1. Load the cascades\n",
    "if not face_cascade.load(cv.samples.findFile(face_cascade_name)):\n",
    "    print('--(!)Error loading face cascade')\n",
    "    exit(0)\n",
    "if not eyes_cascade.load(cv.samples.findFile(eyes_cascade_name)):\n",
    "    print('--(!)Error loading eyes cascade')\n",
    "    exit(0)\n",
    "camera_device = args.camera\n",
    "#-- 2. Read the video stream\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened:\n",
    "    print('--(!)Error opening video capture')\n",
    "    exit(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        print('--(!) No captured frame -- Break!')\n",
    "        break\n",
    "    detectAndDisplay(frame)\n",
    "    if cv.waitKey(10) == 27:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e051063-89f7-47e7-8a40-f92bb62c5578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final video accesssing code\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    # gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('window', frame)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328ca29f-0e04-47f7-9034-8f936c47fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final face detecting code\n",
    "from __future__ import print_function\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "def detectAndDisplay(frame):\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv.equalizeHist(frame_gray)\n",
    "    #-- Detect faces\n",
    "    faces = face_cascade.detectMultiScale(frame_gray)\n",
    "    for (x,y,w,h) in faces:\n",
    "        center = (x + w//2, y + h//2)\n",
    "        frame = cv.ellipse(frame, center, (w//2, h//2), 0, 0, 360, (255, 0, 255), 4)\n",
    "        faceROI = frame_gray[y:y+h,x:x+w]\n",
    "        #-- In each face, detect eyes\n",
    "        eyes = eyes_cascade.detectMultiScale(faceROI)\n",
    "        for (x2,y2,w2,h2) in eyes:\n",
    "            eye_center = (x + x2 + w2//2, y + y2 + h2//2)\n",
    "            radius = int(round((w2 + h2)*0.25))\n",
    "            frame = cv.circle(frame, eye_center, radius, (255, 0, 0 ), 4)\n",
    "    cv.imshow('Capture - Face detection', frame)\n",
    "#parser = argparse.ArgumentParser(description='Code for Cascade Classifier tutorial.')\n",
    "#parser.add_argument('--face_cascade', help='Path to face cascade.', default='data/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "#parser.add_argument('--eyes_cascade', help='Path to eyes cascade.', default='data/haarcascades/haarcascade_eye_tree_eyeglasses.xml')\n",
    "#parser.add_argument('--camera', help='Camera divide number.', type=int, default=0)\n",
    "#args = parser.parse_args()\n",
    "face_cascade_name = 'data/haarcascades/haarcascade_frontalface_alt.xml'\n",
    "eyes_cascade_name = 'data/haarcascades/haarcascade_eye_tree_eyeglasses.xml'\n",
    "face_cascade = cv.CascadeClassifier()\n",
    "eyes_cascade = cv.CascadeClassifier()\n",
    "#-- 1. Load the cascades\n",
    "if not face_cascade.load(cv.samples.findFile(face_cascade_name)):\n",
    "    print('--(!)Error loading face cascade')\n",
    "    exit(0)\n",
    "if not eyes_cascade.load(cv.samples.findFile(eyes_cascade_name)):\n",
    "    print('--(!)Error loading eyes cascade')\n",
    "    exit(0)\n",
    "#camera_device = args.camera\n",
    "#-- 2. Read the video stream\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened:\n",
    "    print('--(!)Error opening video capture')\n",
    "    exit(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        print('--(!) No captured frame -- Break!')\n",
    "        break\n",
    "    detectAndDisplay(frame)\n",
    "    if cv.waitKey(10) == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45040c28-8af2-406b-a090-cff037f93663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac27877-b2b1-42c1-a4b9-296b89487a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths #imutils includes opencv functions\n",
    "import face_recognition\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "#get paths of each file in folder named Images\n",
    "\n",
    "#Images here that contains data(folders of various people)\n",
    "imagePath = list(paths.list_images('/Users/chilanayasadli/Desktop/Images'))\n",
    "kEncodings = []\n",
    "kNames = []\n",
    "# loop over the image paths\n",
    "for (i, ip) in enumerate(imagePath):\n",
    "# extract the person name from the image path\n",
    "    name = ip.split(os.path.sep)[-2]\n",
    "# load the input image and convert it from BGR\n",
    "    image = cv2.imread(ip)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    boxes = face_recognition.face_locations(rgb,model='hog')\n",
    "# compute the facial embedding for the any face\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "# loop over the encodings\n",
    "    for encoding in encodings:\n",
    "        kEncodings.append(encoding)\n",
    "    kNames.append(name)\n",
    "#save emcodings along with their names in dictionary data\n",
    "data = {\"encodings\": kEncodings, \"names\": kNames}\n",
    "#use pickle to save data into a file for later use\n",
    "f = open(\"face_enc\", \"wb\")\n",
    "f.write(pickle.dumps(data)) #to open file in write mode\n",
    "f.close() #to close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5c4ef2-db81-4f0e-b36c-9cd44f719ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import imutils #imutils includes opencv functions\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "#to find path of xml file containing haarCascade file\n",
    "cfp = os.path.dirname(cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
    "# load the harcaascade in the cascade classifier\n",
    "fc = cv2.CascadeClassifier(cfp)\n",
    "# load the known faces and embeddings saved in last file\n",
    "data = pickle.loads(open('face_enc.txt', \"rb\").read())\n",
    "#Find path to the image you want to detect face and pass it here\n",
    "image = cv2.imread(\"/Users/chilanayasadli/Documents/FF2.jpg\")\n",
    "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#convert image to Greyscale for HaarCascade\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = fc.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=6, minSize=(60, 60),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "# the facial embeddings for face in input\n",
    "encodings = face_recognition.face_encodings(rgb)\n",
    "names = []\n",
    "# loop over the facial embeddings incase\n",
    "# we have multiple embeddings for multiple fcaes\n",
    "for encoding in encodings:\n",
    "#Compare encodings with encodings in data[\"encodings\"]\n",
    "#Matches contain array with boolean values True and False\n",
    "    matches = face_recognition.compare_faces(data[\"encodings\"],encoding)\n",
    "#set name =unknown if no encoding matches\n",
    "    name = \"Unknown\"\n",
    "# check to see if we have found a match\n",
    "    if True in matches:\n",
    "#Find positions at which we get True and store them\n",
    "        matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "    count = {}\n",
    "# loop over the matched indexes and maintain a count for\n",
    "# each recognized face face\n",
    "    for i in matchedIdxs:\n",
    "#Check the names at respective indexes we stored in matchedIdxs\n",
    "        name = data[\"names\"][i]\n",
    "#increase count for the name we got\n",
    "        count[name] = count.get(name, 0) + 1\n",
    "#set name which has highest count\n",
    "        name = max(count, key=count.get)\n",
    "# will update the list of names\n",
    "    names.append(name)\n",
    "# do loop over the recognized faces\n",
    "for ((x, y, w, h), name) in zip(faces, names):\n",
    "# rescale the face coordinates\n",
    "# draw the predicted face name on the image\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    cv2.putText(image, name, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Frame\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8888f7ac-b7ec-49b8-b5ce-fd138ef55541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final code 03.02.2022\n",
    "\n",
    "from imutils import paths\n",
    "import face_recognition\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    " \n",
    "#get paths of each file in folder named Images\n",
    "#Images here contains my data(folders of various persons)\n",
    "imagePaths = list(paths.list_images('/Users/chilanayasadli/Desktop/Images2'))\n",
    "knownEncodings = []\n",
    "knownNames = []\n",
    "# loop over the image paths\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # extract the person name from the image path\n",
    "    name = imagePath.split(os.path.sep)[-2]\n",
    "    # load the input image and convert it from BGR (OpenCV ordering)\n",
    "    # to dlib ordering (RGB)\n",
    "    image = cv2.imread(imagePath)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    #Use Face_recognition to locate faces\n",
    "    boxes = face_recognition.face_locations(rgb,model='hog')\n",
    "    # compute the facial embedding for the face\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "    # loop over the encodings\n",
    "    for encoding in encodings:\n",
    "        knownEncodings.append(encoding)\n",
    "        knownNames.append(name)\n",
    "#save emcodings along with their names in dictionary data\n",
    "data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "#use pickle to save data into a file for later use\n",
    "f = open(\"face_enc\", \"wb\")\n",
    "f.write(pickle.dumps(data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d17ced4-d918-4ab6-973e-2e743f0c7e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final code 03.02.2022\n",
    "\n",
    "import face_recognition\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    " \n",
    "#find path of xml file containing haarcascade file\n",
    "cascPathface = os.path.dirname(\n",
    " cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
    "# load the harcaascade in the cascade classifier\n",
    "faceCascade = cv2.CascadeClassifier(cascPathface)\n",
    "# load the known faces and embeddings saved in last file\n",
    "data = pickle.loads(open('face_enc', \"rb\").read())\n",
    "#Find path to the image you want to detect face and pass it here\n",
    "image = cv2.imread(\"/Users/chilanayasadli/Documents/TEST10.jpg\")\n",
    "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#convert image to Greyscale for haarcascade\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(gray,\n",
    "                                     scaleFactor=1.1,\n",
    "                                     minNeighbors=6,\n",
    "                                     minSize=(60, 60),\n",
    "                                     flags=cv2.CASCADE_SCALE_IMAGE)\n",
    " \n",
    "# the facial embeddings for face in input\n",
    "encodings = face_recognition.face_encodings(rgb)\n",
    "names = []\n",
    "# loop over the facial embeddings incase\n",
    "# we have multiple embeddings for multiple fcaes\n",
    "for encoding in encodings:\n",
    "    #Compare encodings with encodings in data[\"encodings\"]\n",
    "    #Matches contain array with boolean values and True for the embeddings it matches closely\n",
    "    #and False for rest\n",
    "    matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "    #set name =inknown if no encoding matches\n",
    "    name = \"Unknown\"\n",
    "    # check to see if we have found a match\n",
    "    if True in matches:\n",
    "        #Find positions at which we get True and store them\n",
    "        matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "        counts = {}\n",
    "        # loop over the matched indexes and maintain a count for\n",
    "        # each recognized face face\n",
    "        for i in matchedIdxs:\n",
    "            #Check the names at respective indexes we stored in matchedIdxs\n",
    "            name = data[\"names\"][i]\n",
    "            #increase count for the name we got\n",
    "            counts[name] = counts.get(name, 0) + 1\n",
    "            #set name which has highest count\n",
    "            name = max(counts, key=counts.get)\n",
    " \n",
    " \n",
    "        # update the list of names\n",
    "        names.append(name)\n",
    "        # loop over the recognized faces\n",
    "        for ((x, y, w, h), name) in zip(faces, names):\n",
    "            # rescale the face coordinates\n",
    "            # draw the predicted face name on the image\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(image, name, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Frame\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1f4306-6302-4e34-a471-6d5e8d01fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final code for face recognition via live stream\n",
    "\n",
    "import face_recognition\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    " \n",
    "#find path of xml file containing haarcascade file \n",
    "cascPathface = os.path.dirname(\n",
    " cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
    "# load the harcaascade in the cascade classifier\n",
    "faceCascade = cv2.CascadeClassifier(cascPathface)\n",
    "# load the known faces and embeddings saved in last file\n",
    "data = pickle.loads(open('face_enc', \"rb\").read())\n",
    " \n",
    "print(\"Streaming started\")\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# loop over frames from the video file stream\n",
    "while True:\n",
    "    # grab the frame from the threaded video stream\n",
    "    ret, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray,\n",
    "                                         scaleFactor=1.1,\n",
    "                                         minNeighbors=5,\n",
    "                                         minSize=(60, 60),\n",
    "                                         flags=cv2.CASCADE_SCALE_IMAGE)\n",
    " \n",
    "    # convert the input frame from BGR to RGB \n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # the facial embeddings for face in input\n",
    "    encodings = face_recognition.face_encodings(rgb)\n",
    "    names = []\n",
    "    # loop over the facial embeddings incase\n",
    "    # we have multiple embeddings for multiple fcaes\n",
    "    for encoding in encodings:\n",
    "       #Compare encodings with encodings in data[\"encodings\"]\n",
    "       #Matches contain array with boolean values and True for the embeddings it matches closely\n",
    "       #and False for rest\n",
    "        matches = face_recognition.compare_faces(data[\"encodings\"],\n",
    "         encoding)\n",
    "        #set name =inknown if no encoding matches\n",
    "        name = \"Unknown\"\n",
    "        # check to see if we have found a match\n",
    "        if True in matches:\n",
    "            #Find positions at which we get True and store them\n",
    "            matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "            counts = {}\n",
    "            # loop over the matched indexes and maintain a count for\n",
    "            # each recognized face face\n",
    "            for i in matchedIdxs:\n",
    "                #Check the names at respective indexes we stored in matchedIdxs\n",
    "                name = data[\"names\"][i]\n",
    "                #increase count for the name we got\n",
    "                counts[name] = counts.get(name, 0) + 1\n",
    "            #set name which has highest count\n",
    "            name = max(counts, key=counts.get)\n",
    " \n",
    " \n",
    "        # update the list of names\n",
    "        names.append(name)\n",
    "        # loop over the recognized faces\n",
    "        for ((x, y, w, h), name) in zip(faces, names):\n",
    "            # rescale the face coordinates\n",
    "            # draw the predicted face name on the image\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, name, (x, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "             0.75, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8049b868-2329-4f56-9a26-788613affd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83710c9b-8757-4b09-920e-68d3b4767802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final code for face recognition via live stream\n",
    "\n",
    "import face_recognition\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    " \n",
    "#find path of xml file containing haarcascade file \n",
    "cascPathface = os.path.dirname(\n",
    " cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
    "# load the harcaascade in the cascade classifier\n",
    "faceCascade = cv2.CascadeClassifier(cascPathface)\n",
    "# load the known faces and embeddings saved in last file\n",
    "data = pickle.loads(open('face_enc', \"rb\").read())\n",
    " \n",
    "print(\"Streaming started\")\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# loop over frames from the video file stream\n",
    "while True:\n",
    "    # grab the frame from the threaded video stream\n",
    "    ret, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray,\n",
    "                                         scaleFactor=1.1,\n",
    "                                         minNeighbors=5,\n",
    "                                         minSize=(60, 60),\n",
    "                                         flags=cv2.CASCADE_SCALE_IMAGE)\n",
    " \n",
    "    # convert the input frame from BGR to RGB \n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # the facial embeddings for face in input\n",
    "    encodings = face_recognition.face_encodings(rgb)\n",
    "    names = []\n",
    "    # loop over the facial embeddings incase\n",
    "    # we have multiple embeddings for multiple fcaes\n",
    "    for encoding in encodings:\n",
    "       #Compare encodings with encodings in data[\"encodings\"]\n",
    "       #Matches contain array with boolean values and True for the embeddings it matches closely\n",
    "       #and False for rest\n",
    "        matches = face_recognition.compare_faces(data[\"encodings\"],\n",
    "         encoding)\n",
    "        #set name =inknown if no encoding matches\n",
    "        name = \"Unknown\"\n",
    "        # check to see if we have found a match\n",
    "        if True in matches:\n",
    "            #Find positions at which we get True and store them\n",
    "            matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "            counts = {}\n",
    "            # loop over the matched indexes and maintain a count for\n",
    "            # each recognized face face\n",
    "            for i in matchedIdxs:\n",
    "                #Check the names at respective indexes we stored in matchedIdxs\n",
    "                name = data[\"names\"][i]\n",
    "                #increase count for the name we got\n",
    "                counts[name] = counts.get(name, 0) + 1\n",
    "            #set name which has highest count\n",
    "            name = max(counts, key=counts.get)\n",
    " \n",
    " \n",
    "        # update the list of names\n",
    "        names.append(name)\n",
    "        # loop over the recognized faces\n",
    "        for ((x, y, w, h), name) in zip(faces, names):\n",
    "            # rescale the face coordinates\n",
    "            # draw the predicted face name on the image\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, name, (x, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "             0.75, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
